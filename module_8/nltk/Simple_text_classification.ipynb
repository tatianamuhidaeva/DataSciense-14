{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1DNiHsB0bvg"
   },
   "source": [
    "# Классификация текста простыми методами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZG4CmD10mnd"
   },
   "source": [
    "Загружем необходимые данные для nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpFTvZC_j0ac",
    "outputId": "7d90af6f-30be-4b2e-8fae-c0c9bc5cae9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikyrc05w1EKV"
   },
   "source": [
    "Мы будем использовать датасет fetch_20newsgroups. Он содержит коллекции новостей с 20 различных источников. Но мы возьмем только 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ivAOt423fyiv"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6O1EiR72oCG",
    "outputId": "438fea57-b722-4ce7-fe43-f851e568b58c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVH0XPGj4zc6"
   },
   "source": [
    "Загружаем данные и таргеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "74KIxchqgr8A"
   },
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WgX3xrFkibXw"
   },
   "outputs": [],
   "source": [
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGtQT3YO48J-"
   },
   "source": [
    "Смотрим на количество данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0qDNIBUhfXb",
    "outputId": "7109ce42-3c2a-4b23-9855-5085af933863"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2373, 2373)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkENH8hHtb81",
    "outputId": "095b44dc-430f-47ab-de5c-e4bc4d7059a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1579, 1579)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iCpZKvs2SbA"
   },
   "source": [
    "TfidfVectorizer – это одновременно CountVectorizer после которого идет TfidfTransformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vld2k-ZAhigO",
    "outputId": "67a5854f-655d-4693-f36c-5144d4505930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2373, 38683)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9T_PY6L2U8q"
   },
   "source": [
    "Воспользуемся LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhRu2fs-hysR",
    "outputId": "1f2d68f4-ea3d-4298-c885-71e53f9e36e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64hdTnSs2eyC"
   },
   "source": [
    "Оценим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vl-fyhWTiINv"
   },
   "outputs": [],
   "source": [
    "X_test_vec = X_train_vec = vectorizer.transform(X_test)\n",
    "y_pred = lr.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlWgYNM7iWQ5",
    "outputId": "cfa4bb43-4e53-4551-f813-bc707a0dc11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      sci.crypt       0.95      0.90      0.93       396\n",
      "sci.electronics       0.80      0.94      0.86       393\n",
      "        sci.med       0.95      0.87      0.91       396\n",
      "      sci.space       0.97      0.93      0.95       394\n",
      "\n",
      "       accuracy                           0.91      1579\n",
      "      macro avg       0.92      0.91      0.91      1579\n",
      "   weighted avg       0.92      0.91      0.91      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KooSMdhx2_Wa"
   },
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUbPbRP35NpP"
   },
   "source": [
    "До этого мы не применяли предобработку. Посмотрим насколько она нам может помочь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lg5XYRZ5Sb0"
   },
   "source": [
    "Рассмотрим сначала предобработку на одном примере.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7XoKWtWuhKW",
    "outputId": "2d5b7be5-5086-4b5f-8626-6e51361e5301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: al@escom.com (Al Donaldson)\n",
      "Subject: Re: Once tapped, your code is no good any more.\n",
      "Reply-To: al@escom.COM (Al Donaldson)\n",
      "Organization: ESCOM Corp., Oakton VA (USA)\n",
      "Distribution: na\n",
      "Lines: 16\n",
      "\n",
      "amolitor@nmsu.edu (Andrew Molitor) writes:\n",
      ">Yes, those evil guys in the FBI can probably, with some\n",
      ">effort, abuse the system. I got news for you, if the evil guys in\n",
      ">the FBI decide they want to persecute you, they're gonna, ...\n",
      "\n",
      "And if Richard Nixon had had this kind of toy, he wouldn't have had\n",
      "to send people into the Watergate.\n",
      "\n",
      "But that's not really the issue.  The real issue is whether this \n",
      "will be used to justify a ban against individuals' use of private \n",
      "(i.e., anything else) encryption methods.\n",
      "\n",
      "Unrelated question...isn't the term \"Clipper,\" as neat as it is,\n",
      "already taken by Intergraph?\n",
      "\n",
      "Al\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = X_train[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll553ZzOut9O"
   },
   "source": [
    "Переведем в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnHPz7zeutCP",
    "outputId": "5fdaa3e2-cc41-4fc4-ea2b-86746810afbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: al@escom.com (al donaldson)\n",
      "subject: re: once tapped, your code is no good any more.\n",
      "reply-to: al@escom.com (al donaldson)\n",
      "organization: escom corp., oakton va (usa)\n",
      "distribution: na\n",
      "lines: 16\n",
      "\n",
      "amolitor@nmsu.edu (andrew molitor) writes:\n",
      ">yes, those evil guys in the fbi can probably, with some\n",
      ">effort, abuse the system. i got news for you, if the evil guys in\n",
      ">the fbi decide they want to persecute you, they're gonna, ...\n",
      "\n",
      "and if richard nixon had had this kind of toy, he wouldn't have had\n",
      "to send people into the watergate.\n",
      "\n",
      "but that's not really the issue.  the real issue is whether this \n",
      "will be used to justify a ban against individuals' use of private \n",
      "(i.e., anything else) encryption methods.\n",
      "\n",
      "unrelated question...isn't the term \"clipper,\" as neat as it is,\n",
      "already taken by intergraph?\n",
      "\n",
      "al\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.lower()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLvNKePU5xh3"
   },
   "source": [
    "Токенизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1irV8YFkHJw",
    "outputId": "050ff22d-81c8-4ee0-c47f-62234325cb30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'subject', ':', 're', ':', 'once', 'tapped', ',', 'your', 'code', 'is', 'no', 'good', 'any', 'more', '.', 'reply-to', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'organization', ':', 'escom', 'corp.', ',', 'oakton', 'va', '(', 'usa', ')', 'distribution', ':', 'na', 'lines', ':', '16', 'amolitor', '@', 'nmsu.edu', '(', 'andrew', 'molitor', ')', 'writes', ':', '>', 'yes', ',', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', ',', 'with', 'some', '>', 'effort', ',', 'abuse', 'the', 'system', '.', 'i', 'got', 'news', 'for', 'you', ',', 'if', 'the', 'evil', 'guys', 'in', '>', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', ',', 'they', \"'re\", 'gon', 'na', ',', '...', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', ',', 'he', 'would', \"n't\", 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', '.', 'but', 'that', \"'s\", 'not', 'really', 'the', 'issue', '.', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', \"'\", 'use', 'of', 'private', '(', 'i.e.', ',', 'anything', 'else', ')', 'encryption', 'methods', '.', 'unrelated', 'question', '...', 'is', \"n't\", 'the', 'term', '``', 'clipper', ',', \"''\", 'as', 'neat', 'as', 'it', 'is', ',', 'already', 'taken', 'by', 'intergraph', '?', 'al']\n"
     ]
    }
   ],
   "source": [
    "x = nltk.word_tokenize(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTQMec6l57za"
   },
   "source": [
    "Удалим слова со знаками препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4fp2MYNj0dD",
    "outputId": "47acd95a-409f-4446-bb7d-af40dcf27f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'is', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'lines', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'got', 'news', 'for', 'you', 'if', 'the', 'evil', 'guys', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'methods', 'unrelated', 'question', 'is', 'the', 'term', 'clipper', 'as', 'neat', 'as', 'it', 'is', 'already', 'taken', 'by', 'intergraph', 'al']\n"
     ]
    }
   ],
   "source": [
    "x = [word for word in x if word.isalnum()]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkBoj68q6AU5"
   },
   "source": [
    "Лемматизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaBPzwyrj0fb",
    "outputId": "4a79b4c9-ab6c-4035-d479-2792b1d96973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'be', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guy', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'get', 'news', 'for', 'you', 'if', 'the', 'evil', 'guy', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'have', 'have', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'have', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'be', 'whether', 'this', 'will', 'be', 'use', 'to', 'justify', 'a', 'ban', 'against', 'individual', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'be', 'the', 'term', 'clipper', 'a', 'neat', 'a', 'it', 'be', 'already', 'take', 'by', 'intergraph', 'al']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "     tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "     tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "     return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "x = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wgylucV6J1p"
   },
   "source": [
    "Удалим стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7Sjl6t6lJiI",
    "outputId": "fbda388f-d4e2-41a8-97d9-0614e23e2bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "['al', 'al', 'donaldson', 'subject', 'tapped', 'code', 'good', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'evil', 'guy', 'fbi', 'probably', 'effort', 'abuse', 'system', 'get', 'news', 'evil', 'guy', 'fbi', 'decide', 'want', 'persecute', 'gon', 'na', 'richard', 'nixon', 'kind', 'toy', 'would', 'send', 'people', 'watergate', 'really', 'issue', 'real', 'issue', 'whether', 'use', 'justify', 'ban', 'individual', 'use', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'term', 'clipper', 'neat', 'already', 'take', 'intergraph', 'al']\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(len(x))\n",
    "x = [word for word in x if not word in stop_words]\n",
    "print(x)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFflSZDLBpiZ",
    "outputId": "4b932ddf-5b6b-4834-a90f-3abf432e30e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [00:10<00:00, 234.96it/s]\n",
      "100%|██████████| 1579/1579 [00:05<00:00, 275.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def preprocces(X):\n",
    "  X_proccess = []\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  for x in tqdm(X):\n",
    "    \n",
    "    x = x.lower()\n",
    "    x = nltk.word_tokenize(x)\n",
    "    x = [word for word in x if word.isalnum()]\n",
    "    x = [lemmatizer.lemmatize(w) for w in x]\n",
    "    x = [word for word in x if not word in stop_words]\n",
    "    X_proccess.append(' '.join(x))\n",
    "  return X_proccess\n",
    "\n",
    "\n",
    "X_train_proc = preprocces(X_train)\n",
    "X_test_proc = preprocces(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEJ_VN2xB1s-",
    "outputId": "31f588d6-0e68-4a1a-f319-91bc26ed3ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2373, 29333)\n",
      "(1579, 29333)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
    "X_test_vec = vectorizer.transform(X_test_proc)\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hsMuhYAB3-B",
    "outputId": "42a73c13-671d-4c65-ab63-4f0e1c84b382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      sci.crypt       0.98      0.92      0.95       396\n",
      "sci.electronics       0.85      0.97      0.90       393\n",
      "        sci.med       0.96      0.92      0.94       396\n",
      "      sci.space       0.98      0.95      0.97       394\n",
      "\n",
      "       accuracy                           0.94      1579\n",
      "      macro avg       0.94      0.94      0.94      1579\n",
      "   weighted avg       0.94      0.94      0.94      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv4KdGEF3pi9"
   },
   "source": [
    "## Стемминг "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjAoIILi7S0b"
   },
   "source": [
    "Воспользуемся стеммингом вместо лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLDlk5ZvsoFl",
    "outputId": "c09a23f0-ce98-44b0-b69c-a78b835c5b02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [00:20<00:00, 114.50it/s]\n",
      "100%|██████████| 1579/1579 [00:11<00:00, 133.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocces(X):\n",
    "  X_proccess = []\n",
    "  stemmer = PorterStemmer()\n",
    "\n",
    "  for x in tqdm(X):\n",
    "    \n",
    "    x = x.lower()\n",
    "    x = nltk.word_tokenize(x)\n",
    "    x = [word for word in x if word.isalnum()]\n",
    "    x = [stemmer.stem(w) for w in x]\n",
    "    x = [word for word in x if not word in stop_words]\n",
    "    X_proccess.append(' '.join(x))\n",
    "  return X_proccess\n",
    "\n",
    "\n",
    "X_train_proc = preprocces(X_train)\n",
    "X_test_proc = preprocces(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0yyJKxgvpZZ",
    "outputId": "764ea24b-b1b0-4d2b-a1e7-2c93d79fe500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2373, 23978)\n",
      "(1579, 23978)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
    "X_test_vec = vectorizer.transform(X_test_proc)\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8INNKEovp6x",
    "outputId": "69ab5f19-0c03-429e-eb40-bdf69497461b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      sci.crypt       0.96      0.92      0.94       396\n",
      "sci.electronics       0.84      0.95      0.89       393\n",
      "        sci.med       0.95      0.91      0.93       396\n",
      "      sci.space       0.99      0.94      0.96       394\n",
      "\n",
      "       accuracy                           0.93      1579\n",
      "      macro avg       0.94      0.93      0.93      1579\n",
      "   weighted avg       0.94      0.93      0.93      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oohUi82MB_c0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6]),\n",
       " (array([0, 0, 1, 2, 2, 2]), array([0, 2, 2, 0, 1, 2])))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data, (row, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Simple text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
