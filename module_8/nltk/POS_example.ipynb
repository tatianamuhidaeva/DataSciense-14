{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nz0d2ocV8HfR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1520/2330079163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torchtext import datasets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "\n",
    "from gensim.models import FastText\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PkiEw2OU8NVo"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzjpe8Nj8PQ8",
    "outputId": "a9b13956-fa3e-4876-88dc-de711b33ebd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688k/688k [00:00<00:00, 2.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, _, test_data = datasets.UDPOS()\n",
    "train_data = [d for d in train_data]\n",
    "test_data = [d for d in test_data]\n",
    "\n",
    "train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n",
    "train_tags = [ d[1] for d in train_data]\n",
    "\n",
    "test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n",
    "test_tags = [d[1] for d in test_data]\n",
    "\n",
    "tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isZGOw9s8Rx1",
    "outputId": "6c8f6286-9216-4d26-b527-522c39ad8599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.']\n",
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n",
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n",
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0])\n",
    "print(train_data[0][1])\n",
    "\n",
    "print(train_tokens[0])\n",
    "print(train_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0Rvxf3us8TZ-"
   },
   "outputs": [],
   "source": [
    "ft = FastText(sentences=train_tokens, size=100, window=5, min_count=1, min_n=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RO-d848s8WCO"
   },
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "pad_inds = len(tag2num)\n",
    "\n",
    "\n",
    "def prepare_data(all_tokens, all_tags, ft, tag2num, max_len, pad_tags):\n",
    "  '''\n",
    "    Из массива слов all_tokens получим тензор векторов, где каждое слово представлено вектором (ft.wv)\n",
    "    А целевую переменную классов all_tags преобразуем в числа.\n",
    "    Все строки не длиннее max_len.\n",
    "    Пустые значения заполняются нулями или pad_tags\n",
    "  '''\n",
    "    \n",
    "    # укорачиваем токены\n",
    "  all_tokens = [tokens[:max_len] for tokens in all_tokens]\n",
    "  all_tags = [tags[:max_len] for tags in all_tags]\n",
    "\n",
    "  # переводим теги в числа\n",
    "  all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n",
    "\n",
    "  # all_ids = []\n",
    "  # for tokens in all_tokens:\n",
    "  #     ids = prepare_sequence(tokens, word_to_ix)\n",
    "  #     all_ids.append(ids)\n",
    "      \n",
    "  X_vecs = []\n",
    "  Y_vecs = []\n",
    "\n",
    "  for tokens, tags in zip(all_tokens, all_tags):\n",
    "      X_vecs.append(torch.tensor(np.row_stack([ft.wv[w] for w in tokens])))\n",
    "      Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n",
    "      \n",
    "  # в качестве заполнителя X используем новый индекс len(word_to_ix)\n",
    "  X = pad_sequence(X_vecs, batch_first=True)\n",
    "\n",
    "  # в качестве заполнителя Y используем pad_tags\n",
    "  Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n",
    "\n",
    "  return X, Y\n",
    "\n",
    "X_train, Y_train = prepare_data(train_tokens, train_tags, ft, tag2num, max_len, pad_inds)\n",
    "\n",
    "# X_train.size(), Y_train.size()\n",
    "\n",
    "X_test, Y_test = prepare_data(test_tokens, test_tags, ft, tag2num, max_len, pad_inds)\n",
    "\n",
    "# X_test.size(), Y_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L8Wea2wg8ffN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "bs = 128\n",
    "data = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "85xUmCFb8kif"
   },
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "    # sentence = [batch size, sent len, emb dim]\n",
    "      sentence = sentence.view(sentence.shape[1], sentence.shape[0], self.input_size)\n",
    "    # sentence = [sent len, batch size, emb dim]\n",
    "\n",
    "      outputs, (hidden, cell) = self.lstm(sentence)\n",
    "\n",
    "      predictions = self.fc(self.dropout(outputs))\n",
    "\n",
    "      # predictions = [sent len, batch size, output dim]\n",
    "      predictions = predictions.view(predictions.shape[1],predictions.shape[0], self.output_dim)\n",
    "      # predictions = [batch size, sent len, output dim]\n",
    "      \n",
    "      # raise NotImplementedException()       \n",
    "      return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oI-nxi_w8mMF"
   },
   "outputs": [],
   "source": [
    "def train_on_epoch(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input, b_tags = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input)  \n",
    "\n",
    "        # outputs = [batch size, sent len, out dim]\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
    "        # outputs = [batch size * sent len, out dim]\n",
    "\n",
    "        # b_tags = [batch size, sent len]\n",
    "        b_tags = b_tags.view(-1)\n",
    "        # b_tags = [batch size * sent len]\n",
    "        \n",
    "        loss = criterion(outputs, b_tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def predict_on_dataloader(model, dataloaded):\n",
    "    model.eval()\n",
    "        \n",
    "    all_outputs = []\n",
    "    all_tags = []\n",
    "    for batch in dataloaded:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input, b_tags = batch\n",
    "        outputs = model(b_input)  \n",
    "        \n",
    "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
    "        b_tags = b_tags.view(-1)\n",
    "\n",
    "        all_outputs.append(outputs)\n",
    "        all_tags.append(b_tags)\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_tags = torch.cat(all_tags)\n",
    "    \n",
    "    return all_outputs, all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePwABW8l9393",
    "outputId": "a4c9f582-c09c-492d-b8ec-c977fba9e9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cJMrAXBv94OP"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(tag2num)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOn7XvEO952U",
    "outputId": "b9abd025-c80f-4571-90a0-52feeddcafa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tLoss 9.883845083465591e-06, accuracy: 0.49271511774509985, f1-macro: 0.26873855130688656\n",
      "1:\tLoss 8.51163066635808e-06, accuracy: 0.5592231098974766, f1-macro: 0.3677729977123259\n",
      "2:\tLoss 7.6861043017055e-06, accuracy: 0.5918805390013346, f1-macro: 0.4330344111015487\n",
      "3:\tLoss 7.118146602829307e-06, accuracy: 0.6162905834670996, f1-macro: 0.46122097842590876\n",
      "4:\tLoss 6.734568607153403e-06, accuracy: 0.6352823237821116, f1-macro: 0.4849428384815078\n",
      "5:\tLoss 6.4475724460112385e-06, accuracy: 0.6476441754767923, f1-macro: 0.4972731928366662\n",
      "6:\tLoss 6.231278375546207e-06, accuracy: 0.6536713469498208, f1-macro: 0.5046255016381151\n",
      "7:\tLoss 6.043796680894111e-06, accuracy: 0.6602827850452345, f1-macro: 0.5145501487376035\n",
      "8:\tLoss 5.901720926821849e-06, accuracy: 0.6670479775149603, f1-macro: 0.5233966207870386\n",
      "9:\tLoss 5.744919327959877e-06, accuracy: 0.6748710000799523, f1-macro: 0.5335470172933718\n",
      "10:\tLoss 5.620300798765649e-06, accuracy: 0.6802216523060081, f1-macro: 0.5410919734936509\n",
      "11:\tLoss 5.492505496004727e-06, accuracy: 0.688493637643991, f1-macro: 0.5503715185816529\n",
      "12:\tLoss 5.401549549300208e-06, accuracy: 0.691710179154597, f1-macro: 0.5581778683859657\n",
      "13:\tLoss 5.296276493384894e-06, accuracy: 0.6988074810728365, f1-macro: 0.5731950416110807\n",
      "14:\tLoss 5.213248917174308e-06, accuracy: 0.7032663579278831, f1-macro: 0.5905345584713485\n",
      "15:\tLoss 5.125895708828139e-06, accuracy: 0.7076637330332048, f1-macro: 0.6147415342354402\n",
      "16:\tLoss 5.051738977706452e-06, accuracy: 0.7116859474652054, f1-macro: 0.6323565565032807\n",
      "17:\tLoss 4.976298853524878e-06, accuracy: 0.7154129534985271, f1-macro: 0.633422998612685\n",
      "18:\tLoss 4.909747536802934e-06, accuracy: 0.7180206276868577, f1-macro: 0.6435284961746057\n",
      "19:\tLoss 4.833983356790185e-06, accuracy: 0.7220551424688032, f1-macro: 0.6510926905245578\n",
      "20:\tLoss 4.789367393943589e-06, accuracy: 0.7233343788630786, f1-macro: 0.6543760864607847\n",
      "21:\tLoss 4.723346517026746e-06, accuracy: 0.7272335897956297, f1-macro: 0.6479991180654865\n",
      "22:\tLoss 4.664530383668613e-06, accuracy: 0.7297367110094282, f1-macro: 0.6609397144282179\n",
      "23:\tLoss 4.608135871148418e-06, accuracy: 0.7327010953461626, f1-macro: 0.6611405790807251\n",
      "24:\tLoss 4.5654899038184855e-06, accuracy: 0.7341955878644747, f1-macro: 0.6667198499241448\n",
      "25:\tLoss 4.4945253425812625e-06, accuracy: 0.7389435229432277, f1-macro: 0.6707127948691055\n",
      "26:\tLoss 4.452540317178487e-06, accuracy: 0.7406040701857968, f1-macro: 0.6746581389914768\n",
      "27:\tLoss 4.414425632800076e-06, accuracy: 0.742227716378531, f1-macro: 0.6773637315652481\n",
      "28:\tLoss 4.374916115347437e-06, accuracy: 0.7439497653708248, f1-macro: 0.6820861835162303\n",
      "29:\tLoss 4.319848252208486e-06, accuracy: 0.7473446619556326, f1-macro: 0.684012996114545\n",
      "30:\tLoss 4.282397808968184e-06, accuracy: 0.7481380345270823, f1-macro: 0.6880176763789185\n",
      "31:\tLoss 4.232491378072371e-06, accuracy: 0.7504689508416514, f1-macro: 0.6935003588209363\n",
      "32:\tLoss 4.2099343062222825e-06, accuracy: 0.7516866854862021, f1-macro: 0.6964208774256071\n",
      "33:\tLoss 4.154258655110383e-06, accuracy: 0.7548478754220558, f1-macro: 0.6990474353698095\n",
      "34:\tLoss 4.121167202694168e-06, accuracy: 0.7571849419115974, f1-macro: 0.7036830065283922\n",
      "35:\tLoss 4.0955521288716174e-06, accuracy: 0.7574309489104964, f1-macro: 0.7043454112682167\n",
      "36:\tLoss 4.048818072594563e-06, accuracy: 0.7606782412959648, f1-macro: 0.706519720644443\n",
      "37:\tLoss 4.0121363455058135e-06, accuracy: 0.7628123520114147, f1-macro: 0.7112483955224786\n",
      "38:\tLoss 3.98078944252462e-06, accuracy: 0.7641715406803323, f1-macro: 0.7136819124192553\n",
      "39:\tLoss 3.953311047672817e-06, accuracy: 0.765413876024773, f1-macro: 0.7154710684869423\n",
      "40:\tLoss 3.919991949700992e-06, accuracy: 0.7679354477634889, f1-macro: 0.7200550202918564\n",
      "41:\tLoss 3.882881691767624e-06, accuracy: 0.769171632932957, f1-macro: 0.7204335218929387\n",
      "42:\tLoss 3.864976140779267e-06, accuracy: 0.7701126097037461, f1-macro: 0.7233161518543524\n",
      "43:\tLoss 3.81855111059461e-06, accuracy: 0.7725357786429023, f1-macro: 0.7252979333589595\n",
      "44:\tLoss 3.774974032618543e-06, accuracy: 0.7756539173539487, f1-macro: 0.7308446739161116\n",
      "45:\tLoss 3.7574145322010323e-06, accuracy: 0.7753956100051046, f1-macro: 0.7320066732271836\n",
      "46:\tLoss 3.7159485826545275e-06, accuracy: 0.7778433796441508, f1-macro: 0.7348587140567012\n",
      "47:\tLoss 3.654493813693688e-06, accuracy: 0.7813920306032707, f1-macro: 0.7395638363445144\n",
      "48:\tLoss 3.6342993434634163e-06, accuracy: 0.7824191098236745, f1-macro: 0.7401880994101631\n",
      "49:\tLoss 3.5943810904318636e-06, accuracy: 0.7845962717639317, f1-macro: 0.7414550444351309\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for e in range(epochs):\n",
    "    train_on_epoch(model, dataloader, optimizer)    \n",
    "    \n",
    "    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n",
    "    loss = criterion(all_outputs, all_tags).item()\n",
    "    all_outputs = all_outputs.detach().cpu().numpy()\n",
    "    all_tags = all_tags.detach().cpu().numpy()\n",
    "    \n",
    "    mask = all_tags != pad_inds\n",
    "    loss = loss/len(all_tags[mask]) \n",
    "    all_tags = all_tags[mask]\n",
    "    all_preds = np.argmax(all_outputs, axis=1)[mask]\n",
    "    \n",
    "    print(f\"{e}:\\tLoss {loss}, \"\n",
    "          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n",
    "          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XqItfFw9-OHN"
   },
   "outputs": [],
   "source": [
    "def count_metrics(model, dataloader):\n",
    "  y_pred, y_true = predict_on_dataloader(model, dataloader)\n",
    "\n",
    "  y_pred = y_pred.detach().cpu().numpy()\n",
    "  y_true = y_true.detach().cpu().numpy()\n",
    "\n",
    "  mask = y_true != pad_inds\n",
    "  y_true = y_true[mask]\n",
    "  y_pred = np.argmax(y_pred, axis=1)[mask]\n",
    "\n",
    "  print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt3K_kBa_qte",
    "outputId": "8cde61e4-cc0d-4ec0-aebe-a6a016b18c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.33      0.44      9962\n",
      "           1       0.89      0.85      0.87     13578\n",
      "           2       0.72      0.65      0.68      8547\n",
      "           3       0.85      0.95      0.90     10404\n",
      "           4       0.99      0.98      0.99      5202\n",
      "           5       0.95      0.98      0.96     13014\n",
      "           6       0.94      0.62      0.75       649\n",
      "           7       0.55      0.85      0.67     27080\n",
      "           8       0.93      0.95      0.94      3339\n",
      "           9       0.79      0.90      0.84      4484\n",
      "          10       0.95      0.95      0.95     15619\n",
      "          11       0.81      0.15      0.25     10523\n",
      "          12       0.99      1.00      0.99     16990\n",
      "          13       0.77      0.59      0.67      3134\n",
      "          14       0.92      0.65      0.76       484\n",
      "          15       0.71      0.69      0.70     18849\n",
      "          16       0.99      0.13      0.24       739\n",
      "\n",
      "    accuracy                           0.78    162597\n",
      "   macro avg       0.85      0.72      0.74    162597\n",
      "weighted avg       0.80      0.78      0.77    162597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_metrics(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtV5E59A_tHn",
    "outputId": "480abe36-1d01-4908-f114-3a27a7b7d5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.32      0.42      1466\n",
      "           1       0.85      0.81      0.83      1656\n",
      "           2       0.64      0.60      0.62      1066\n",
      "           3       0.82      0.93      0.87      1336\n",
      "           4       0.98      0.98      0.98       599\n",
      "           5       0.95      0.96      0.96      1607\n",
      "           6       0.86      0.44      0.59       115\n",
      "           7       0.50      0.81      0.61      3446\n",
      "           8       0.90      0.96      0.93       448\n",
      "           9       0.71      0.80      0.75       546\n",
      "          10       0.92      0.93      0.93      1923\n",
      "          11       0.67      0.08      0.14      1773\n",
      "          12       0.98      0.99      0.98      2467\n",
      "          13       0.67      0.48      0.56       330\n",
      "          14       0.70      0.43      0.53        81\n",
      "          15       0.61      0.68      0.64      2306\n",
      "          16       0.00      0.00      0.00       114\n",
      "\n",
      "    accuracy                           0.73     21279\n",
      "   macro avg       0.73      0.66      0.67     21279\n",
      "weighted avg       0.75      0.73      0.71     21279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "data = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n",
    "count_metrics(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-xBF81k_vZr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "POS_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
