{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1DNiHsB0bvg"
   },
   "source": [
    "# Классификация текста простыми методами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpFTvZC_j0ac",
    "outputId": "90a2f630-8f6e-4f99-cc95-1d15e4371cb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TANYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\TANYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TANYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TANYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ivAOt423fyiv"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\"comp.sys.mac.hardware\", \"comp.windows.x\",  \"misc.forsale\", \"rec.autos\", \"rec.motorcycles\", \"rec.sport.baseball\", \"rec.sport.hockey\", \"sci.crypt\", \"sci.electronics\", \"sci.med\",\n",
    "              \"sci.space\", \"soc.religion.christian\", \"talk.politics.guns\", \"talk.politics.mideast\"]\n",
    "              \n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0qDNIBUhfXb",
    "outputId": "d3dc8e16-fca3-4992-c3c8-1f8daff4fc5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8227, 8227)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkENH8hHtb81",
    "outputId": "1ea6f0a4-7bc1-4585-daa4-f9fbaf957391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5477, 5477)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8227/8227 [00:24<00:00, 341.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5477/5477 [00:15<00:00, 363.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocces(X):\n",
    "  X_proccess = []\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  for x in tqdm(X):\n",
    "    \n",
    "    x = x.lower()\n",
    "    x = nltk.word_tokenize(x)\n",
    "    x = [word for word in x if word.isalnum()]\n",
    "    x = [lemmatizer.lemmatize(w) for w in x]\n",
    "    x = [word for word in x if not word in stop_words]\n",
    "    X_proccess.append(' '.join(x))\n",
    "  return X_proccess\n",
    "\n",
    "\n",
    "X_train_proc = preprocces(X_train)\n",
    "X_test_proc = preprocces(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8227, 62970)\n",
      "(5477, 62970)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
    "X_test_vec = vectorizer.transform(X_test_proc)\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*стандартизация результат не улучшила*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8227x62970 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 852092 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      " comp.sys.mac.hardware       0.90      0.92      0.91       385\n",
      "        comp.windows.x       0.92      0.93      0.92       395\n",
      "          misc.forsale       0.79      0.89      0.84       390\n",
      "             rec.autos       0.91      0.88      0.89       396\n",
      "       rec.motorcycles       0.96      0.94      0.95       398\n",
      "    rec.sport.baseball       0.94      0.95      0.94       397\n",
      "      rec.sport.hockey       0.96      0.96      0.96       399\n",
      "             sci.crypt       0.97      0.90      0.94       396\n",
      "       sci.electronics       0.78      0.87      0.82       393\n",
      "               sci.med       0.94      0.87      0.91       396\n",
      "             sci.space       0.97      0.94      0.95       394\n",
      "soc.religion.christian       0.94      0.95      0.95       398\n",
      "    talk.politics.guns       0.95      0.93      0.94       364\n",
      " talk.politics.mideast       0.99      0.93      0.96       376\n",
      "\n",
      "              accuracy                           0.92      5477\n",
      "             macro avg       0.92      0.92      0.92      5477\n",
      "          weighted avg       0.92      0.92      0.92      5477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стандартизация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8227x62970 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 852092 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_sc = scaler.fit_transform(X_train_vec)\n",
    "X_test_sc = scaler.transform(X_test_vec)\n",
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      " comp.sys.mac.hardware       0.86      0.89      0.87       385\n",
      "        comp.windows.x       0.92      0.90      0.91       395\n",
      "          misc.forsale       0.78      0.86      0.82       390\n",
      "             rec.autos       0.91      0.88      0.89       396\n",
      "       rec.motorcycles       0.93      0.94      0.93       398\n",
      "    rec.sport.baseball       0.88      0.95      0.91       397\n",
      "      rec.sport.hockey       0.94      0.96      0.95       399\n",
      "             sci.crypt       0.94      0.90      0.92       396\n",
      "       sci.electronics       0.82      0.79      0.81       393\n",
      "               sci.med       0.90      0.78      0.83       396\n",
      "             sci.space       0.93      0.88      0.90       394\n",
      "soc.religion.christian       0.86      0.97      0.91       398\n",
      "    talk.politics.guns       0.93      0.93      0.93       364\n",
      " talk.politics.mideast       0.96      0.90      0.93       376\n",
      "\n",
      "              accuracy                           0.90      5477\n",
      "             macro avg       0.90      0.90      0.90      5477\n",
      "          weighted avg       0.90      0.90      0.89      5477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TANYA\\.conda\\envs\\env-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "y_pred = lr.predict(X_test_sc)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стемминг \n",
    "\n",
    "Воспользуемся стеммингом вместо лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8227/8227 [00:47<00:00, 174.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5477/5477 [00:29<00:00, 183.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocces(X):\n",
    "  X_proccess = []\n",
    "  stemmer = PorterStemmer()\n",
    "\n",
    "  for x in tqdm(X):\n",
    "    \n",
    "    x = x.lower()\n",
    "    x = nltk.word_tokenize(x)\n",
    "    x = [word for word in x if word.isalnum()]\n",
    "    x = [stemmer.stem(w) for w in x]\n",
    "    x = [word for word in x if not word in stop_words]\n",
    "    X_proccess.append(' '.join(x))\n",
    "  return X_proccess\n",
    "\n",
    "\n",
    "X_train_proc = preprocces(X_train)\n",
    "X_test_proc = preprocces(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8227, 52550)\n",
      "(5477, 52550)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
    "X_test_vec = vectorizer.transform(X_test_proc)\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      " comp.sys.mac.hardware       0.89      0.90      0.89       385\n",
      "        comp.windows.x       0.92      0.94      0.93       395\n",
      "          misc.forsale       0.79      0.88      0.83       390\n",
      "             rec.autos       0.92      0.89      0.90       396\n",
      "       rec.motorcycles       0.97      0.94      0.95       398\n",
      "    rec.sport.baseball       0.95      0.94      0.94       397\n",
      "      rec.sport.hockey       0.96      0.97      0.96       399\n",
      "             sci.crypt       0.95      0.90      0.92       396\n",
      "       sci.electronics       0.76      0.85      0.80       393\n",
      "               sci.med       0.94      0.89      0.91       396\n",
      "             sci.space       0.97      0.93      0.95       394\n",
      "soc.religion.christian       0.93      0.95      0.94       398\n",
      "    talk.politics.guns       0.94      0.93      0.93       364\n",
      " talk.politics.mideast       0.99      0.92      0.96       376\n",
      "\n",
      "              accuracy                           0.92      5477\n",
      "             macro avg       0.92      0.92      0.92      5477\n",
      "          weighted avg       0.92      0.92      0.92      5477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "y_pred = lr.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Simple text classification task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
