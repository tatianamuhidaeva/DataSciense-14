{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_task_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsP7cV1_arhs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchtext import datasets\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import random\n",
        "\n",
        "from gensim.models import FastText\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNRfW260a3jg"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyk3BCHza5ru",
        "outputId": "4eefd7f1-ff88-4abb-e181-6106c105c7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, _, test_data = datasets.UDPOS()\n",
        "train_data = [d for d in train_data]\n",
        "test_data = [d for d in test_data]\n",
        "\n",
        "train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n",
        "train_tags = [ d[1] for d in train_data]\n",
        "\n",
        "test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n",
        "test_tags = [d[1] for d in test_data]\n",
        "\n",
        "tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688k/688k [00:00<00:00, 2.19MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBDDAUdhbxCq"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "word_to_ix = {}\n",
        "for tokens in train_tokens:\n",
        "    for word in tokens:\n",
        "        word = stemmer.stem(word)\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "word_to_ix[\"UNK\"] =  len(word_to_ix)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hkWDYVab5PT",
        "outputId": "7c8df957-51d0-42b0-813b-996b16157d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_len = 20\n",
        "pad_inds = len(tag2num)\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(w) for w in seq]\n",
        "    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n",
        "    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n",
        "    \n",
        "    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n",
        "    all_tags = [tags[:max_len] for tags in all_tags]\n",
        "    \n",
        "    all_ids = []\n",
        "    for tokens in all_tokens:\n",
        "        ids = prepare_sequence(tokens, word_to_ix)\n",
        "        all_ids.append(ids)\n",
        "        \n",
        "    X_vecs = []\n",
        "    Y_vecs = []\n",
        "\n",
        "    for ids, tags in zip(all_ids, all_tags):\n",
        "        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n",
        "        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n",
        "        \n",
        "    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n",
        "    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n",
        "\n",
        "    # в качестве заполнителя Y используем pad_tags\n",
        "    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "# X_train = X_train.view(X_train.shape[0],X_train.shape[1], 1)\n",
        "\n",
        "X_train.size(), Y_train.size()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12543, 20]), torch.Size([12543, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYNHAQxZcHhS",
        "outputId": "3848f86d-d2a2-489e-e9aa-e3aea42d1a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "# X_test = X_test.view(X_test.shape[0],X_test.shape[1], 1)\n",
        "X_test.size(), Y_test.size()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2077, 20]), torch.Size([2077, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfjixGEdceuN",
        "outputId": "f9e1fd78-c62a-47a9-dcef-85c67c7db400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11, 12, 11,  ...,  7,  1,  5],\n",
            "        [12,  5,  7,  ..., 12, 17, 17],\n",
            "        [11, 12,  0,  ..., 17, 17, 17],\n",
            "        ...,\n",
            "        [ 2, 10,  3,  ...,  2,  3,  5],\n",
            "        [ 5,  7,  1,  ...,  1,  7, 10],\n",
            "        [10,  3,  2,  ...,  7, 10,  2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8RSqbmOckWA"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "bs = 128\n",
        "data = TensorDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5lgGR7Dcl0X"
      },
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # padding_idx=pad_idx - это номер id \"заполнителя\". \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0, batch_first = True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "      emb = self.embedding(text)\n",
        "\n",
        "      outputs, (hidden, cell) = self.lstm(emb)\n",
        "\n",
        "      predictions = self.fc(self.dropout(outputs))\n",
        "        # raise NotImplementedException()       \n",
        "      return predictions"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHtLZSe8dBWV"
      },
      "source": [
        "def train_on_epoch(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input)  \n",
        "\n",
        "        # outputs = [batch size, sent len, out dim]\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        # outputs = [batch size * sent len, out dim]\n",
        "\n",
        "        # b_tags = [batch size, sent len]\n",
        "        b_tags = b_tags.view(-1)\n",
        "        # b_tags = [batch size * sent len]\n",
        "        \n",
        "        loss = criterion(outputs, b_tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def predict_on_dataloader(model, dataloaded):\n",
        "    model.eval()\n",
        "        \n",
        "    all_outputs = []\n",
        "    all_tags = []\n",
        "    for batch in dataloaded:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        outputs = model(b_input)  \n",
        "        \n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        b_tags = b_tags.view(-1)\n",
        "\n",
        "        all_outputs.append(outputs)\n",
        "        all_tags.append(b_tags)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs)\n",
        "    all_tags = torch.cat(all_tags)\n",
        "    \n",
        "    return all_outputs, all_tags"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9HPx3ywdDUj",
        "outputId": "b4eeefcf-198b-4652-9707-2823e1cb8a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "print(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uDf2IvsdEeg"
      },
      "source": [
        "INPUT_DIM = len(word_to_ix)+1\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(tag2num)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = len(word_to_ix)\n",
        "\n",
        "model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWu61Ea-dKbc",
        "outputId": "4af3589c-3d09-4e62-cf2a-3f56b5d0af36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 50\n",
        "for e in range(epochs):\n",
        "    train_on_epoch(model, dataloader, optimizer)    \n",
        "    \n",
        "    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n",
        "    loss = criterion(all_outputs, all_tags).item()\n",
        "    all_outputs = all_outputs.detach().cpu().numpy()\n",
        "    all_tags = all_tags.detach().cpu().numpy()\n",
        "    \n",
        "    mask = all_tags != pad_inds\n",
        "    loss = loss/len(all_tags[mask]) \n",
        "    all_tags = all_tags[mask]\n",
        "    all_preds = np.argmax(all_outputs, axis=1)[mask]\n",
        "    \n",
        "    print(f\"{e}:\\tLoss {loss}, \"\n",
        "          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n",
        "          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tLoss 3.537471167845344e-06, accuracy: 0.8122720591400825, f1-macro: 0.6993875544923663\n",
            "1:\tLoss 2.6544424889510667e-06, accuracy: 0.858908835956383, f1-macro: 0.7750336075600806\n",
            "2:\tLoss 2.105053115885361e-06, accuracy: 0.8885711298486442, f1-macro: 0.8159497516995727\n",
            "3:\tLoss 1.704041722966068e-06, accuracy: 0.9108101625491245, f1-macro: 0.8546219531309603\n",
            "4:\tLoss 1.4059223637477966e-06, accuracy: 0.9269666722018242, f1-macro: 0.8815100406628613\n",
            "5:\tLoss 1.1491975628168432e-06, accuracy: 0.9411981770881381, f1-macro: 0.9062793193189735\n",
            "6:\tLoss 9.453672698109553e-07, accuracy: 0.9522131404638462, f1-macro: 0.9217444041380548\n",
            "7:\tLoss 7.82523899250456e-07, accuracy: 0.9611800955737191, f1-macro: 0.936209903138962\n",
            "8:\tLoss 6.542197848451113e-07, accuracy: 0.9681605441674815, f1-macro: 0.9469201601084116\n",
            "9:\tLoss 5.42366315221165e-07, accuracy: 0.9739171079417209, f1-macro: 0.956310350724368\n",
            "10:\tLoss 4.454646405146874e-07, accuracy: 0.9786158416206941, f1-macro: 0.9632264478758837\n",
            "11:\tLoss 3.673361863654587e-07, accuracy: 0.9832100223251351, f1-macro: 0.9704785702904647\n",
            "12:\tLoss 3.188708233195612e-07, accuracy: 0.9849382214924015, f1-macro: 0.9741860719393043\n",
            "13:\tLoss 2.3603487627837217e-07, accuracy: 0.9898891123452462, f1-macro: 0.9818878520990166\n",
            "14:\tLoss 1.9985378154022958e-07, accuracy: 0.9913774546885858, f1-macro: 0.9853223284801522\n",
            "15:\tLoss 1.6639455874774143e-07, accuracy: 0.992884247556843, f1-macro: 0.9886180866645125\n",
            "16:\tLoss 1.3137400728394148e-07, accuracy: 0.9945386446244395, f1-macro: 0.9905016054722464\n",
            "17:\tLoss 1.0422033268774102e-07, accuracy: 0.9959285841682196, f1-macro: 0.9926309728299664\n",
            "18:\tLoss 8.843427844005521e-08, accuracy: 0.9965928030652472, f1-macro: 0.9937840408488052\n",
            "19:\tLoss 8.917957935833148e-08, accuracy: 0.996242243091816, f1-macro: 0.99331056120657\n",
            "20:\tLoss 6.575988412832293e-08, accuracy: 0.9975460801859813, f1-macro: 0.9957895386270889\n",
            "21:\tLoss 5.462523618643268e-08, accuracy: 0.9981241966333942, f1-macro: 0.9965446901687689\n",
            "22:\tLoss 4.830547732630972e-08, accuracy: 0.9983025517075961, f1-macro: 0.9971958635523152\n",
            "23:\tLoss 4.2965143078242164e-08, accuracy: 0.9984194050320732, f1-macro: 0.9973215507501654\n",
            "24:\tLoss 2.920900855723384e-08, accuracy: 0.9990897741040733, f1-macro: 0.9982208388568995\n",
            "25:\tLoss 2.7184905408196315e-08, accuracy: 0.9991697263787155, f1-macro: 0.9985142951985696\n",
            "26:\tLoss 2.7099446680093933e-08, accuracy: 0.9990713235791558, f1-macro: 0.9986084530014078\n",
            "27:\tLoss 2.1458656555574872e-08, accuracy: 0.9993665319778348, f1-macro: 0.9987072357328349\n",
            "28:\tLoss 1.881358720512438e-08, accuracy: 0.9993849825027522, f1-macro: 0.9990077135108244\n",
            "29:\tLoss 1.781569904011736e-08, accuracy: 0.999434183902532, f1-macro: 0.9990990644891942\n",
            "30:\tLoss 1.3017807195323525e-08, accuracy: 0.9996617403765137, f1-macro: 0.9994837129469102\n",
            "31:\tLoss 1.1977158879357567e-08, accuracy: 0.999692491251376, f1-macro: 0.9995971406196512\n",
            "32:\tLoss 1.262806212666652e-08, accuracy: 0.9996494400265687, f1-macro: 0.9995514071907313\n",
            "33:\tLoss 1.039043029318183e-08, accuracy: 0.9997355424761835, f1-macro: 0.9996492867044671\n",
            "34:\tLoss 8.64493935156368e-09, accuracy: 0.9997601431760733, f1-macro: 0.999684121043218\n",
            "35:\tLoss 7.761085892842871e-09, accuracy: 0.9997970442259082, f1-macro: 0.9997720083422391\n",
            "36:\tLoss 7.828764823735415e-09, accuracy: 0.9998031944008807, f1-macro: 0.9997209596950052\n",
            "37:\tLoss 8.05826546953067e-09, accuracy: 0.9997601431760733, f1-macro: 0.9997156706568362\n",
            "38:\tLoss 6.441205335455055e-09, accuracy: 0.9997970442259082, f1-macro: 0.9997659965701904\n",
            "39:\tLoss 5.6688849677725585e-09, accuracy: 0.9998031944008807, f1-macro: 0.9997763825619752\n",
            "40:\tLoss 6.206570435812429e-09, accuracy: 0.9998339452757431, f1-macro: 0.9998270160245886\n",
            "41:\tLoss 5.763586927944324e-09, accuracy: 0.9998339452757431, f1-macro: 0.9997780674960088\n",
            "42:\tLoss 5.9311231941066656e-09, accuracy: 0.9997601431760733, f1-macro: 0.9997668591767638\n",
            "43:\tLoss 7.052667690044706e-09, accuracy: 0.9997232421262385, f1-macro: 0.9997351022174875\n",
            "44:\tLoss 5.168251543203384e-09, accuracy: 0.9998154947508257, f1-macro: 0.9997994077004895\n",
            "45:\tLoss 4.207005168221996e-09, accuracy: 0.9998523958006605, f1-macro: 0.9998196936323049\n",
            "46:\tLoss 4.877266578743651e-09, accuracy: 0.9998031944008807, f1-macro: 0.9997386001923708\n",
            "47:\tLoss 6.477828868128422e-09, accuracy: 0.9997662933510458, f1-macro: 0.9997690692701598\n",
            "48:\tLoss 4.949716764362016e-09, accuracy: 0.9997908940509358, f1-macro: 0.9997777220504\n",
            "49:\tLoss 5.438527300382644e-09, accuracy: 0.9997847438759633, f1-macro: 0.9997290382940572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kcXubKVdVov"
      },
      "source": [
        "def count_metrics(model, dataloader):\n",
        "  y_pred, y_true = predict_on_dataloader(model, dataloader)\n",
        "\n",
        "  y_pred = y_pred.detach().cpu().numpy()\n",
        "  y_true = y_true.detach().cpu().numpy()\n",
        "\n",
        "  mask = y_true != pad_inds\n",
        "  y_true = y_true[mask]\n",
        "  y_pred = np.argmax(y_pred, axis=1)[mask]\n",
        "\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25kR8EZsdavw",
        "outputId": "71a03d33-9846-4b45-f511-d434f2c348b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count_metrics(model, dataloader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      9962\n",
            "           1       1.00      1.00      1.00     13578\n",
            "           2       1.00      1.00      1.00      8547\n",
            "           3       1.00      1.00      1.00     10404\n",
            "           4       1.00      1.00      1.00      5202\n",
            "           5       1.00      1.00      1.00     13014\n",
            "           6       1.00      1.00      1.00       649\n",
            "           7       1.00      1.00      1.00     27080\n",
            "           8       1.00      1.00      1.00      3339\n",
            "           9       1.00      1.00      1.00      4484\n",
            "          10       1.00      1.00      1.00     15619\n",
            "          11       1.00      1.00      1.00     10523\n",
            "          12       1.00      1.00      1.00     16990\n",
            "          13       1.00      1.00      1.00      3134\n",
            "          14       1.00      1.00      1.00       484\n",
            "          15       1.00      1.00      1.00     18849\n",
            "          16       1.00      1.00      1.00       739\n",
            "\n",
            "    accuracy                           1.00    162597\n",
            "   macro avg       1.00      1.00      1.00    162597\n",
            "weighted avg       1.00      1.00      1.00    162597\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAOUiigWdY7m",
        "outputId": "dd8df662-63cc-4925-fea6-27e4216c71d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = TensorDataset(X_test, Y_test)\n",
        "test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n",
        "count_metrics(model, test_dataloader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      1466\n",
            "           1       0.93      0.96      0.95      1656\n",
            "           2       0.78      0.86      0.82      1066\n",
            "           3       0.96      0.97      0.97      1336\n",
            "           4       0.99      0.99      0.99       599\n",
            "           5       0.99      0.99      0.99      1607\n",
            "           6       0.98      0.76      0.85       115\n",
            "           7       0.83      0.86      0.85      3446\n",
            "           8       0.88      0.59      0.71       448\n",
            "           9       0.94      0.97      0.96       546\n",
            "          10       0.98      0.99      0.98      1923\n",
            "          11       0.84      0.57      0.68      1773\n",
            "          12       0.85      1.00      0.92      2467\n",
            "          13       0.92      0.79      0.85       330\n",
            "          14       0.83      0.79      0.81        81\n",
            "          15       0.89      0.89      0.89      2306\n",
            "          16       0.17      0.10      0.12       114\n",
            "\n",
            "    accuracy                           0.88     21279\n",
            "   macro avg       0.86      0.82      0.83     21279\n",
            "weighted avg       0.88      0.88      0.88     21279\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W32kZg1qdbSj"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}